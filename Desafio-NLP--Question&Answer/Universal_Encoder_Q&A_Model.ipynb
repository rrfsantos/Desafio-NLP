{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Universal Encoder Q&A Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOUkBo0tBgutKs4kaTs+j92",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1f9ddc96784f45bb8469a448ca629c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_18028d3847514d99b3efdb30ab55d317",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8ff1ff0f4e324df49336360d3c786e91",
              "IPY_MODEL_5ed1b8d32a6d41328793f3d0409829b5"
            ]
          }
        },
        "18028d3847514d99b3efdb30ab55d317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ff1ff0f4e324df49336360d3c786e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_12119932fc2143698d5f60677e861249",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 34,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 34,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fab460b9d41e47f2ae1229467797fe58"
          }
        },
        "5ed1b8d32a6d41328793f3d0409829b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2c28b2dafde4d1cbc77ee2b8c18e5ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 34/34 [04:59&lt;00:00,  8.81s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00192e1a26684a2e8c3a31568db174a9"
          }
        },
        "12119932fc2143698d5f60677e861249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fab460b9d41e47f2ae1229467797fe58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2c28b2dafde4d1cbc77ee2b8c18e5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00192e1a26684a2e8c3a31568db174a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrfsantos/Desafios-NLP/blob/main/Desafio-NLP--Question%26Answer/Universal_Encoder_Q%26A_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0up_CL3u5rkX"
      },
      "source": [
        "### Recuperação de perguntas e respostas utilizando codificador universal de frases multilíngue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzQvdksl682Z"
      },
      "source": [
        "##### https://www.tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haHGBIVt6gS5"
      },
      "source": [
        "Being able to automatically answer questions accurately remains a difficult problem in natural language processing. This dataset has everything you need to try your own hand at this task. Can you correctly generate the answer to questions given the Wikipedia article text the question was originally generated from?\n",
        "\n",
        "Content:\n",
        "There are three question files, one for each year of students: S08, S09, and S10, as well as 690,000 words worth of cleaned text from Wikipedia that was used to generate the questions.\n",
        "\n",
        "The \"questionanswerpairs.txt\" files contain both the questions and answers. The columns in this file are as follows:\n",
        "\n",
        "ArticleTitle is the name of the Wikipedia article from which questions and answers initially came.\n",
        "Question is the question.\n",
        "Answer is the answer.\n",
        "DifficultyFromQuestioner is the prescribed difficulty rating for the question as given to the question-writer.\n",
        "DifficultyFromAnswerer is a difficulty rating assigned by the individual who evaluated and answered the question, which may differ from the difficulty in field 4.\n",
        "ArticleFile is the name of the file with the relevant article\n",
        "\n",
        "Questions that were judged to be poor were discarded from this data set.\n",
        "There are frequently multiple lines with the same question, which appear if those questions were answered by multiple individuals. https://www.kaggle.com/rtatman/questionanswer-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B76aWJCFWgy4"
      },
      "source": [
        "### Solução"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HTvivU22083"
      },
      "source": [
        "##### Cada resposta no dataset QA (Sxx_question_answer_pairs.txt) e seu contexto (o texto em torno da frase) em seu artigo correspondente (Sxx_setx_ax.txt.clean), são codificados em embeddings de alta dimensão com o response_encoder. Esses embeddings são armazenados em um índice construído usando a biblioteca simpleneighbors para recuperação de perguntas e respostas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_9jjAKk8uum"
      },
      "source": [
        "!python -m pip install -q tensorflow_text\n",
        "!python -m pip install -q simpleneighbors[annoy]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxKtBdysta4_"
      },
      "source": [
        "#import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import re\n",
        "import os\n",
        "import tqdm.notebook as tq\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow_text import SentencepieceTokenizer\n",
        "from simpleneighbors import SimpleNeighbors\n",
        "import random\n",
        "import pprint\n",
        "from IPython.display import HTML, display"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipfc2SSrsJzy",
        "outputId": "9ec056a9-4e81-4b1b-b687-afb5f0069c34"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "workdir_path = '/content/drive/My Drive/desafio 3/'  # Inserir o local da pasta onde estão os arquivos de entrada (treino e teste)\n",
        "os.chdir(workdir_path)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK5La8lw4ITt"
      },
      "source": [
        "#### Extrair o **contexto** dos artigos Sxx_setx_ax.txt.clean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRMdggmHErwT"
      },
      "source": [
        "files = glob.glob('/content/drive/My Drive/desafio 3/text_data/*.clean')\n",
        "\n",
        "list_text = []\n",
        "list_file = []\n",
        "\n",
        "for file in files:\n",
        "  with open(file, 'r', encoding = 'utf-8', errors='ignore') as f:\n",
        "    text = f.read()\n",
        "  list_text.append(re.sub(r'\\n+', ' ', text).strip())\n",
        "  list_file.append((os.path.basename(file)).split('.')[0])\n",
        "df_context = pd.DataFrame({'Context': list_text, 'ArticleFile': list_file})"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMPARX6a4p9a"
      },
      "source": [
        "#### Criar dataframes de QA Sxx_question_answer_pairs.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c0hlpqFagq3",
        "outputId": "f5122e7f-9648-4c6c-e97c-89429085d358"
      },
      "source": [
        "df_08 = pd.read_table('S08_question_answer_pairs.txt')\n",
        "df_09 = pd.read_table('S09_question_answer_pairs.txt')\n",
        "df_10 = pd.read_table('S10_question_answer_pairs.txt', engine = 'python', error_bad_lines = False)\n",
        "\n",
        "df_qa = pd.concat([df_08, df_09, df_10], axis=0, ignore_index=True)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping line 765: '\t' expected after '\"'\n",
            "Skipping line 876: '\t' expected after '\"'\n",
            "Skipping line 1219: '\t' expected after '\"'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ03H85y12_4"
      },
      "source": [
        "df_qa.drop(['DifficultyFromQuestioner', 'DifficultyFromAnswerer', 'ArticleTitle'], axis = 1, inplace=True)\n",
        "#df_09.drop(['DifficultyFromQuestioner', 'DifficultyFromAnswerer', 'ArticleTitle'], axis = 1, inplace=True)\n",
        "#df_10.drop(['DifficultyFromQuestioner', 'DifficultyFromAnswerer', 'ArticleTitle'], axis = 1, inplace=True)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHIjq2P71N40",
        "outputId": "7c6d43ec-3c6d-4339-9d0e-0e2da7b3b2cb"
      },
      "source": [
        "# Verifica se há dados faltantes na base\n",
        "print('-' * 15, df_qa.isna().sum(), sep='\\n')\n",
        "#print('-' * 15, df_09.isna().sum(), sep='\\n')\n",
        "#print('-' * 15, df_10.isna().sum(), sep='\\n')"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------\n",
            "Question        37\n",
            "Answer         576\n",
            "ArticleFile      2\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFfUvyiM1fcL",
        "outputId": "dc421a99-e3be-4c52-a2cd-069f9a4e7612"
      },
      "source": [
        "# Remove os dados faltantes da base de treino\n",
        "df_qa.dropna(inplace=True)\n",
        "#df_09.dropna(inplace=True)\n",
        "#df_10.dropna(inplace=True)\n",
        "print('-' * 15, df_qa.isna().sum(), sep='\\n')\n",
        "#print('-' * 15, df_09.isna().sum(), sep='\\n')\n",
        "#print('-' * 15, df_10.isna().sum(), sep='\\n')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------\n",
            "Question       0\n",
            "Answer         0\n",
            "ArticleFile    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnME4pBOBkx_"
      },
      "source": [
        "df_qac = df_qa.merge(df_context, on='ArticleFile')\n",
        "#df_USE09 = df_09.merge(df_context, on='ArticleFile')\n",
        "#df_USE10 = df_10.merge(df_context, on='ArticleFile')"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILFD5BjT4eCh",
        "outputId": "5189d3e7-df7a-4cd1-e55f-b379d22c8537"
      },
      "source": [
        "print('-' * 15, df_qac.shape, sep='\\n')\n",
        "#print('-' * 15, df_09.shape, sep='\\n')\n",
        "#print('-' * 15, df_10.shape, sep='\\n')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------\n",
            "(3417, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "cQ5mo3cFfUoQ",
        "outputId": "9f81686c-c567-4059-f0c2-654fa9720137"
      },
      "source": [
        "df_qac.head()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>ArticleFile</th>\n",
              "      <th>Context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>yes</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "      <td>Abraham Lincoln Abraham Lincoln (February 12, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "      <td>Abraham Lincoln Abraham Lincoln (February 12, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>yes</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "      <td>Abraham Lincoln Abraham Lincoln (February 12, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "      <td>Abraham Lincoln Abraham Lincoln (February 12, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Did his mother die of pneumonia?</td>\n",
              "      <td>no</td>\n",
              "      <td>S08_set3_a4</td>\n",
              "      <td>Abraham Lincoln Abraham Lincoln (February 12, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question  ...                                            Context\n",
              "0  Was Abraham Lincoln the sixteenth President of...  ...  Abraham Lincoln Abraham Lincoln (February 12, ...\n",
              "1  Was Abraham Lincoln the sixteenth President of...  ...  Abraham Lincoln Abraham Lincoln (February 12, ...\n",
              "2  Did Lincoln sign the National Banking Act of 1...  ...  Abraham Lincoln Abraham Lincoln (February 12, ...\n",
              "3  Did Lincoln sign the National Banking Act of 1...  ...  Abraham Lincoln Abraham Lincoln (February 12, ...\n",
              "4                   Did his mother die of pneumonia?  ...  Abraham Lincoln Abraham Lincoln (February 12, ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rbzr7tKNrJG"
      },
      "source": [
        "answer_context = []\n",
        "question = []\n",
        "\n",
        "for index, r in df_qac.iterrows():\n",
        "  answer_context.append((r['Answer'].lower(),r['Context'].lower()))\n",
        "  question.append(r['Question'].lower())"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmD0QsyFxvrl"
      },
      "source": [
        "### Carregar modelo **Universal Encoder Q&A Model** do tensorflow hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLBifqk_PFIu"
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-multilingual-qa/3\"\n",
        "model = hub.load(module_url)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wT7dttqyEmO"
      },
      "source": [
        "### Computar embeddings e criar o **simpleneighbors** index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B21PE-ovxWDA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "1f9ddc96784f45bb8469a448ca629c39",
            "18028d3847514d99b3efdb30ab55d317",
            "8ff1ff0f4e324df49336360d3c786e91",
            "5ed1b8d32a6d41328793f3d0409829b5",
            "12119932fc2143698d5f60677e861249",
            "fab460b9d41e47f2ae1229467797fe58",
            "e2c28b2dafde4d1cbc77ee2b8c18e5ef",
            "00192e1a26684a2e8c3a31568db174a9"
          ]
        },
        "outputId": "6c045298-7aae-4318-bbde-4c6a6d139e77"
      },
      "source": [
        "batch_size = 100\n",
        "\n",
        "encodings = model.signatures['response_encoder'](  input=tf.constant([answer_context[0][0]]), context=tf.constant([answer_context[0][1]]))\n",
        "index = SimpleNeighbors(len(encodings['outputs'][0]), metric='angular')\n",
        "\n",
        "print('Computing embeddings for %s sentences' % len(answer_context))\n",
        "slices = zip(*(iter(answer_context),) * batch_size)\n",
        "num_batches = int(len(answer_context) / batch_size)\n",
        "for s in tq.tqdm_notebook(slices, total=num_batches):\n",
        "  response_batch = list([r for r, c in s])\n",
        "  context_batch = list([c for r, c in s])\n",
        "  encodings = model.signatures['response_encoder'](\n",
        "    input=tf.constant(response_batch),\n",
        "    context=tf.constant(context_batch)\n",
        "  )\n",
        "  for batch_index, batch in enumerate(response_batch):\n",
        "    index.add_one(batch, encodings['outputs'][batch_index])\n",
        "\n",
        "index.build()\n",
        "print('simpleneighbors index for %s sentences built.' % len(answer_context))\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing embeddings for 3417 sentences\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f9ddc96784f45bb8469a448ca629c39",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=34.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "simpleneighbors index for 3417 sentences built.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPDPm7fe1TcI"
      },
      "source": [
        "### Testar o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE-Tdqth1gvn"
      },
      "source": [
        "#### A questão é codificada usando **question_encoder** e o **embedding** da questão é usado para consultar o índice simpleneighbors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M5OIP6rGhXX"
      },
      "source": [
        "def output_with_highlight(text, highlight):\n",
        "  output = \"<li> \"\n",
        "  i = text.find(highlight)\n",
        "  while True:\n",
        "    if i == -1:\n",
        "      output += text\n",
        "      break\n",
        "    output += text[0:i]\n",
        "    output += '<b>'+text[i:i+len(highlight)]+'</b>'\n",
        "    text = text[i+len(highlight):]\n",
        "    i = text.find(highlight)\n",
        "  return output + \"</li>\\n\"\n",
        "\n",
        "def display_nearest_neighbors(query_text, answer_text=None):\n",
        "    query_embedding = model.signatures['question_encoder'](tf.constant([query_text]))['outputs'][0]\n",
        "    search_results = index.nearest(query_embedding, n=num_results)\n",
        "\n",
        "    if answer_text:\n",
        "      result_md = '''\n",
        "      <p>Random Question:</p>\n",
        "      <p>&nbsp;&nbsp;<b>%s</b></p>\n",
        "      <p>Answer:</p>\n",
        "      <p>&nbsp;&nbsp;<b>%s</b></p>\n",
        "      ''' % (query_text , answer_text)\n",
        "    else:\n",
        "      result_md = '''\n",
        "      <p>Question:</p>\n",
        "      <p>&nbsp;&nbsp;<b>%s</b></p>\n",
        "      ''' % query_text\n",
        "\n",
        "    result_md += '''\n",
        "      <p>Retrieved sentences :\n",
        "      <ol>\n",
        "    '''\n",
        "\n",
        "    if answer_text:\n",
        "      for s in search_results:\n",
        "        result_md += output_with_highlight(s, answer_text)\n",
        "    else:\n",
        "      for s in search_results:\n",
        "        result_md += '<li>' + s + '</li>\\n'\n",
        "\n",
        "    result_md += \"</ol>\"\n",
        "    display(HTML(result_md))"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QNcQoUZxgzB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "a149b1cd-77e8-42fc-c1bd-7e4f8ca5943c"
      },
      "source": [
        "#@title ###### Acessar os \"vizinhos próximos\" **nearest neighbors** para perguntas escolhidas randomicamente\n",
        "num_results = 5 #@param {type:\"slider\", min:5, max:40, step:1}\n",
        "\n",
        "query = random.choice(question)\n",
        "display_nearest_neighbors(query)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "      <p>Question:</p>\n",
              "      <p>&nbsp;&nbsp;<b>what shape are the eggs of the larest species of turtle?</b></p>\n",
              "      \n",
              "      <p>Retrieved sentences :\n",
              "      <ol>\n",
              "    <li>turtles lay eggs on land.</li>\n",
              "<li>they lay eggs</li>\n",
              "<li>they lay eggs</li>\n",
              "<li>a female turtle</li>\n",
              "<li>a female turtle.</li>\n",
              "</ol>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}
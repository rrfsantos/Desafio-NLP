{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python383jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
      "display_name": "Python 3.8.3 64-bit ('base': conda)"
    },
    "colab": {
      "name": "insert_label_iob_separados.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrfsantos/Desafios-NLP/blob/main/Desafio-NLP--NER/insert_label_iob_convert_spacy_arquivos_separados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_1p-iVITiIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28b1d407-a02c-414a-a261-b0b04f1b36a5"
      },
      "source": [
        "!pip install --user spacy==3.0.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy==3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/62/a98c61912ea57344816dd4886ed71e34d8aeec55b79e5bed05a7c2a1ae52/spacy-3.0.0-cp37-cp37m-manylinux2014_x86_64.whl (12.7MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7MB 293kB/s \n",
            "\u001b[?25hCollecting pathy\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/53/97dc0197cca9357369b3b71bf300896cf2d3604fa60ffaaf5cbc277de7de/pathy-0.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (54.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (1.19.5)\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/0a/52ae1c659fc08f13dd7c0ae07b88e4f807ad83fb9954a59b0b0a3d1a8ab6/pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (0.8.2)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Collecting srsly<3.0.0,>=2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/54/76982427ceb495dd19ff982c966708c624b85e03c45bf1912feaf60c7b2d/srsly-2.4.0-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 47.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (0.4.1)\n",
            "Collecting thinc<8.1.0,>=8.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/08/20e707519bcded1a0caa6fd024b767ac79e4e5d0fb92266bb7dcf735e338/thinc-8.0.2-cp37-cp37m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 47.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (2.23.0)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/78/d8/e25bc7f99877de34def57d36769f0cce4e895b374cdc766718efc724f9ac/spacy_legacy-3.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (20.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (2.11.3)\n",
            "Collecting catalogue<2.1.0,>=2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/48/5c/493a2f3bb0eac17b1d48129ecfd251f0520b6c89493e9fd0522f534a9e4a/catalogue-2.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.0) (2.0.5)\n",
            "Collecting smart-open<4.0.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 38.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy==3.0.0) (3.4.1)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.0) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.0.0) (1.1.1)\n",
            "Building wheels for collected packages: smart-open\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107098 sha256=0ff5f3c4f3cb7215487113fc81e1cb3cadffc0bd7c48b2ccef77aab572cac188\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n",
            "Successfully built smart-open\n",
            "Installing collected packages: smart-open, typer, pathy, pydantic, catalogue, srsly, thinc, spacy-legacy, spacy\n",
            "\u001b[33m  WARNING: The script pathy is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "\u001b[33m  WARNING: The script spacy is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed catalogue-2.0.1 pathy-0.4.0 pydantic-1.7.3 smart-open-3.0.0 spacy-3.0.0 spacy-legacy-3.0.2 srsly-2.4.0 thinc-8.0.2 typer-0.3.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "catalogue",
                  "spacy",
                  "srsly",
                  "thinc"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJHBgCZSTiIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47bad964-199b-47dd-9c42-f3a718e8e231"
      },
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "import glob\n",
        "import csv\n",
        "\n",
        "import spacy\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(spacy.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zi2RSDuPoos",
        "outputId": "a849742b-f2d6-4cf3-efaf-fb55b8a99ed0"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "workdir_path = '/content/drive/My Drive/desafio 2' #MODIFICAR!!! #Caminho para o seu workspace\n",
        "os.chdir(workdir_path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fheoC1OOSqSY"
      },
      "source": [
        "## Ler arquivos IOB e incluir o nome da classe à tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYx9Di2-rgOU"
      },
      "source": [
        "dirs = ['s800','linnaeus','BC5CDR-disease','NCBI-disease','BC2GM','JNLPBA','BC4CHEMD','BC5CDR-chem']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyZkeIlgcHvk"
      },
      "source": [
        "#### Arquivos de treino"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qad8D8uaTiIe"
      },
      "source": [
        "for dir in dirs:\n",
        "    df = pd.read_csv('NERdata/' + dir + '/train.tsv', sep='\\t', header=None, names=['token','tag'],\n",
        "                         quoting=csv.QUOTE_NONE, error_bad_lines=False, skipinitialspace = True)\n",
        "    if (dir == 's800' or dir == 'linnaeus'):\n",
        "      df['tag'] = df['tag'].replace(['B','I'],['B-SPECIES','I-SPECIES'])\n",
        "    elif (dir == 'BC5CDR-disease' or dir == 'NCBI-disease'):\n",
        "      df['tag'] = df['tag'].replace(['B','I'],['B-DISEASE','I-DISEASE'])\n",
        "    elif (dir == 'BC2GM' or dir == 'JNLPBA'):\n",
        "      df['tag'] = df['tag'].replace(['B','I'],['B-DRUG_PROTEIN','I-DRUG_PROTEIN'])\n",
        "    else:\n",
        "      df['tag'] = df['tag'].replace(['B','I'],['B-CHEMICALS','I-CHEMICALS'])\n",
        "\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    df.to_csv('IOBdata/iob_train_' + dir + '.iob', sep='\\t', index=False, header=False)  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jl4SvT8POH_"
      },
      "source": [
        "## Converter arquivos em formato IOB para o formato binário .spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmgvSH_TPOIA",
        "outputId": "4999f2da-4d97-41ab-f606-d5e747095ea4"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_train_s800.iob ./SPACYdata"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-10 19:28:28.505040: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (685 documents):\n",
            "SPACYdata/iob_train_s800.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "987M-M-UPOIC",
        "outputId": "e1b1c113-ed29-43cd-a38e-213eb6324daf"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_train_linnaeus.iob ./SPACYdata"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-10 19:31:40.287384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (1335 documents):\n",
            "SPACYdata/iob_train_linnaeus.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X-ESrLiPOIE",
        "outputId": "22541898-51d9-4ffa-d8ac-0a47e237b976"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_train_BC5CDR-disease.iob ./SPACYdata"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 01:48:28.255353: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (582 documents):\n",
            "SPACYdata/iob_train_BC5CDR-disease.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdtdaX9xPOIF",
        "outputId": "7dc7d7d7-a738-4df7-8bdc-eff7be49dca1"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_train_NCBI-disease.iob ./SPACYdata"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 01:50:34.079466: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (590 documents):\n",
            "SPACYdata/iob_train_NCBI-disease.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0Jx5BkbPOIF",
        "outputId": "b5172e93-b3e5-4543-daa7-0777d1df5b4b"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_train_BC2GM.iob ./SPACYdata"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-10 19:45:13.022844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (1510 documents):\n",
            "SPACYdata/iob_train_BC2GM.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YKWkcAyPOIG",
        "outputId": "6f594d3e-57de-44ea-97ff-80d41844f553"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_train_JNLPBA.iob ./SPACYdata"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-10 20:08:47.972433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (1610 documents):\n",
            "SPACYdata/iob_train_JNLPBA.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql8UQhfRPOIH",
        "outputId": "95086abc-f921-4cb0-b3df-1c1c2d322405"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_train_BC5CDR-chem.iob ./SPACYdata"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-10 21:47:08.643617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (582 documents):\n",
            "SPACYdata/iob_train_BC5CDR-chem.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBRA2x3sPOII",
        "outputId": "93edd50b-78cd-4abb-99e5-e030b3c6b9d9"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_train_BC4CHEMD.iob ./SPACYdata"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-10 21:49:14.103205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (3732 documents):\n",
            "SPACYdata/iob_train_BC4CHEMD.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2k7UIn2-BLj"
      },
      "source": [
        "#### Arquivos de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDMVr8ti4Xjj"
      },
      "source": [
        "for dir in dirs:\n",
        "    df = pd.read_csv('NERdata/' + dir + '/test.tsv', sep='\\t', header=None, names=['token','tag'],\n",
        "                         quoting=csv.QUOTE_NONE, error_bad_lines=False, skipinitialspace = True)\n",
        "    if (dir == 's800' or dir == 'linnaeus'):\n",
        "      df['tag'] = df['tag'].replace(['B','I'],['B-SPECIES','I-SPECIES'])\n",
        "    elif (dir == 'BC5CDR-disease' or dir == 'NCBI-disease'):\n",
        "      df['tag'] = df['tag'].replace(['B','I'],['B-DISEASE','I-DISEASE'])\n",
        "    elif (dir == 'BC2GM' or dir == 'JNLPBA'):\n",
        "      df['tag'] = df['tag'].replace(['B','I'],['B-DRUG_PROTEIN','I-DRUG_PROTEIN'])\n",
        "    else:\n",
        "      df['tag'] = df['tag'].replace(['B','I'],['B-CHEMICALS','I-CHEMICALS'])\n",
        "\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    df.to_csv('IOBdata/iob_test_' + dir + '.iob', sep='\\t', index=False, header=False)  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zIpanitxSf5",
        "outputId": "57b6d0fd-d220-4b0c-bc0e-00736fb18ba6"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_test_s800.iob ./SPACYdata"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 02:36:45.901932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (202 documents):\n",
            "SPACYdata/iob_test_s800.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiTItNMexYg7",
        "outputId": "cf871629-342a-4b3c-b6a8-261b2183c577"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_test_linnaeus.iob ./SPACYdata"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 02:37:07.072339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (801 documents):\n",
            "SPACYdata/iob_test_linnaeus.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaAVKAhsxi6f",
        "outputId": "d87f0226-f39e-4840-fe19-be6835dfa2c3"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_test_BC5CDR-disease.iob ./SPACYdata"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 02:46:23.811542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (650 documents):\n",
            "SPACYdata/iob_test_BC5CDR-disease.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPbqmflaxreQ",
        "outputId": "694c98d5-abd0-45d2-d963-bd819a0af6ae"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_test_NCBI-disease.iob ./SPACYdata"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 02:51:17.162749: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (98 documents):\n",
            "SPACYdata/iob_test_NCBI-disease.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiKeeX3BxyNH",
        "outputId": "e398c08d-b05e-4fbd-a40c-21127c892de6"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_test_BC2GM.iob ./SPACYdata"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 02:51:27.137633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (611 documents):\n",
            "SPACYdata/iob_test_BC2GM.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY_ct7DLx4i3",
        "outputId": "7beba713-b5df-47a8-a7d6-2783107d8567"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_test_JNLPBA.iob ./SPACYdata"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 02:58:02.086551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (429 documents):\n",
            "SPACYdata/iob_test_JNLPBA.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZVROxiOx9g5",
        "outputId": "d7001c7c-7d3d-453d-d5b7-8249f36d5b9c"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_test_BC5CDR-chem.iob ./SPACYdata"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 03:01:19.245979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (650 documents):\n",
            "SPACYdata/iob_test_BC5CDR-chem.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVdlkyxlyCmQ",
        "outputId": "8c1c5164-4a3d-485c-dc0d-74861d5d3839"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_test_BC4CHEMD.iob ./SPACYdata"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 03:05:44.651508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (3238 documents):\n",
            "SPACYdata/iob_test_BC4CHEMD.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dZL57igqO44"
      },
      "source": [
        "#### Arquivos de Validação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YUD4XhKqV4G"
      },
      "source": [
        "for dir in dirs:\n",
        "    df = pd.read_csv('NERdata/' + dir + '/devel.tsv', sep='\\t', header=None, names=['token','tag'],\n",
        "                         quoting=csv.QUOTE_NONE, error_bad_lines=False, skipinitialspace = True)\n",
        "    if (dir == 's800' or dir == 'linnaeus'):\n",
        "      df['tag'] = df['tag'].replace(['B','I'],['B-SPECIES','I-SPECIES'])\n",
        "    elif (dir == 'BC5CDR-disease' or dir == 'NCBI-disease'):\n",
        "      df['tag'] = df['tag'].replace(['B','I'],['B-DISEASE','I-DISEASE'])\n",
        "    elif (dir == 'BC2GM' or dir == 'JNLPBA'):\n",
        "      df['tag'] = df['tag'].replace(['B','I'],['B-DRUG_PROTEIN','I-DRUG_PROTEIN'])\n",
        "    else:\n",
        "      df['tag'] = df['tag'].replace(['B','I'],['B-CHEMICALS','I-CHEMICALS'])\n",
        "\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    df.to_csv('IOBdata/iob_devel_' + dir + '.iob', sep='\\t', index=False, header=False)  "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_5GyV1xPOIN",
        "outputId": "92ca1772-3a01-4385-ff17-fd794914b462"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_devel_s800.iob ./SPACYdata"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 06:33:16.744773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (101 documents):\n",
            "SPACYdata/iob_devel_s800.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5VVOVRyyxEV",
        "outputId": "5d5e5943-0cec-4497-d232-7765014c9cc5"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_devel_linnaeus.iob ./SPACYdata"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 06:33:25.828508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (485 documents):\n",
            "SPACYdata/iob_devel_linnaeus.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDdv-Tk1y15R",
        "outputId": "36f4912f-26fb-40f8-8324-c4624961a683"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_devel_BC5CDR-disease.iob ./SPACYdata"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 06:35:25.229959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (592 documents):\n",
            "SPACYdata/iob_devel_BC5CDR-disease.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAp7quuyy6lQ",
        "outputId": "78106db8-7195-4ee5-bd51-0f7afe58cc80"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_devel_NCBI-disease.iob ./SPACYdata"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 06:39:19.132970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (96 documents):\n",
            "SPACYdata/iob_devel_NCBI-disease.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzm0uKyUy_lx",
        "outputId": "6c7c30af-39fa-4768-ea4b-a7b604309a58"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_devel_BC2GM.iob ./SPACYdata"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 06:39:28.778502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (313 documents):\n",
            "SPACYdata/iob_devel_BC2GM.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLNeDmjzzEmr",
        "outputId": "a8ce3e52-a777-4d7c-a1a7-ef0f87f9735d"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_devel_JNLPBA.iob ./SPACYdata"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 06:40:21.673695: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (426 documents):\n",
            "SPACYdata/iob_devel_JNLPBA.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXdzS09HzE6t",
        "outputId": "0488d392-6ec0-492d-bda6-d746f2dc188f"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_devel_BC5CDR-chem.iob ./SPACYdata"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 06:43:56.395318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (592 documents):\n",
            "SPACYdata/iob_devel_BC5CDR-chem.spacy\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekT6DZVQzQJ8",
        "outputId": "dc368a4c-dd70-4494-c532-2afd2f44927a"
      },
      "source": [
        "!python -m spacy convert -c iob -s -n 10 IOBdata/iob_devel_BC4CHEMD.iob ./SPACYdata"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 12:55:37.256668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;4mℹ Segmenting sentences with sentencizer. (Use `-b model` for improved\n",
            "parser-based sentence segmentation.)\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}